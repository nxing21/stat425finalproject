---
title: "finalproject"
output:
  pdf_document: default
  html_document: default
date: "2024-04-07"
---


```{r echo=FALSE}
library(ggplot2)
# Reading the data from the file
insurance = read.csv("insurance.csv")
attach(insurance)
insmod = lm(charges~., data = insurance)
summary(insmod)
```

Section 1: Introduction
Provide a brief introduction of the goal of this final project. What is it all about? Where did you get the data from? What is the data framework? What are the main questions you want to answer with this data analysis?

The data comes from the Kaggle data sets. The link can be found here: https://www.kaggle.com/datasets/mirichoi0218/insurance/data

Section 2: Exploratory Data Analysis
Include some graphical displays and numerical summaries of the data. Also comment on any patterns/characteristics of the data which you find interesting or anything relevant to your later analysis.

Provide a brief explanation/summary of variables you plan to include in your analysis. Here are some question you might ask:

Which variables are categorical (when applicable) and which are numerical?
Should we remove any unusual observations?
Should we add or remove some variables in our analysis?
For categorical variables (when applicable), should we include any interactions?
For numerical variables, any evidence supporting nonlinear trends?

Here is a brief overview of all of the variables of this dataset:

Numerical Variables:

- age: age of primary beneficiary
- bmi: body mass index
- children: number of children/dependents covered by health insurance
- charges (response variable): medical costs billed by health insurance

Categorical Variables:

- sex: male or female
- smoker: yes or no
- region: residential area in the US, can be northeast, southeast, southwest, or northwest

```{r echo=FALSE}
# Checking for unusual observations (outliers)
n=1338; p=8;
stud <- rstudent(insmod)
```

Firstly, we performed an outlier test to check if there are any unusual observations. To do so, we obtained the studentized residuals for our data, and compared the largest values with the Bonferroni critical value.

This is the Bonferroni critical value we calculated:

```{r echo=FALSE}
qt(.05/(2*n), n-p-1) # Bonferroni critical value
```

Next, here are the five largest studentized residuals, which we will be comparing to the Bonferroni critical value:

```{r echo=FALSE}
sort(abs(stud), decreasing=TRUE)[1:5] # largest 5 studentized residuals
# 1301 and 578 are unusual observations, we should remove them
```

Since the absolute value of their respective studentized residual is greater than the Bonferroni critical value, we can conclude that Observation #1301 and Observation #578 are outliers. We will be removing these points.

```{r echo=FALSE}
insurance2 = insurance[-c(1301,578),]
attach(insurance2)
insmod2 = lm(charges~., data = insurance2) # new model with the two outliers removed
summary(insmod2)
```

After removing these two points, we will be analyzing the predictors to see if there are any variables we should add or remove.

```{r echo=FALSE}
boxplot(charges ~ age, data = insurance2)
```

From the boxplot of charges vs age, we notice a trend that the charges increase as age increases. We will not be removing 'age' as a predictor since it is clear that it has a significant impact on the response variable 'charges'. This makes sense because as people grow older, their health declines, and the insurance costs increase.

```{r echo=FALSE}
boxplot(charges ~ sex, data=insurance2)
```

The charges vs sex boxplot tells us that males tend to have higher charges than females. We will conduct a t-test to test this difference.

We obtained this p-value from the t-test:

```{r echo=FALSE}
t.test(charges ~ sex, data=insurance2, var.equal=TRUE)[3] # p-value of 'sex'
```

Given that the p-value is less than 0.05, we conclude that 'sex' is a significant predictor, with males incurring higher insurance costs than females. A possible explanation for this is that males are usually more at risk of health conditions that result in increased charges compared to females.

```{r echo=FALSE}
plot(bmi, charges)
```

From the plot of charges vs bmi, we can see a general trend that as bmi increases, the charges also increase. As a result, we will not be removing 'bmi' as a predictor since it appears to have an impact on the response variable. The graph also makes sense logically since people with a higher bmi tend to be overweight and subsequently, have worse health than people with a lower bmi, causing their insurance charges to be greater as well.

```{r echo=FALSE}
boxplot(charges ~ children, data=insurance2)
```

The boxplot of charges vs children conveys to us that charges tend to increase as the number of children grows from 0 or 1 to 2 or 3. While there are some data points for people with 4 or 5 children, it appears that these groups have a very low amount of people, and it may be challenging to draw meaningful conclusions from it. We perform an ANOVA test to test the significance of 'children' as a predictor.

This is the p-value we obtain:

```{r echo=FALSE}
insmodchildren = lm(charges ~ children, data=insurance2)
anova(insmodchildren)[1,5] # p-value of 'children'
```

This p-value is less than 0.05, thus signifying that the predictor 'children' is significant. We will be keeping as a predictor in our model. A larger number of children/dependents covered leads to higher charges, as there are more individuals who need to be covered.

```{r echo=FALSE}
boxplot(charges ~ smoker, data=insurance2)
```

From the boxplot of charges vs smoker, it is evident that smokers generally face significantly higher charges than non-smokers. Consequently, we will not be removing 'smoker' as a predictor. People who smoke typically incur higher insurance costs due to the health risks posed by smoking.

```{r echo=FALSE}
boxplot(charges ~ region, data=insurance2)
```

The boxplot of charges vs region shows us that the southeast region seemingly has higher charges than the other three regions. We will conduct an ANOVA test to make sure that the predictor 'region' is significant.

This is the p-value we obtained from the ANOVA test:

```{r echo=FALSE}
insmodreg = lm(charges ~ region, data=insurance2)
anova(insmodreg)[1,5] # p-value of 'region'
```

The p-value is less than 0.05, indicating that the predictor 'region' is significant, and thus we will retain it as a predictor. This confirms that there are regional differences in the insurance costs.

\newpage

Now, we will explore whether or not we should include any interactions between categorical variables. We will be analyzing the following three interactions.

- 'sex' and 'smoker'
- 'sex' and 'region'
- 'region' and 'smoker'

We will first test the interaction between 'sex' and 'smoker'.

```{r echo=FALSE}
ggplot(insurance2, aes(x = paste(sex, smoker), y = charges)) + geom_boxplot()
```

From the plot, although smoking increases the charges for both males and females, the impact is greater for males. We will fit the model with the interaction as a predictor and check the significance.

Here is the p-value we obtained from the test:

```{r echo=FALSE}
mod1 = lm(charges ~ sex*smoker, data=insurance2)
anova(mod1)[3,5]
```

The p-value is less than 0.05, so this interaction is significant and we will include it in our final model.

We will now test the interaction between 'sex' and 'region'.

```{r echo=FALSE}
ggplot(insurance2, aes(x = paste(sex, region), y = charges)) + geom_boxplot()
```

Overall, it appears as though the interaction between sex and region does not have much of an impact on charges. Once again, we will fit the model with the interaction and conduct a test to truly find out whether the interaction is significant.

This is the p-value we obtained from our test:

```{r echo=FALSE}
mod2 = lm(charges ~ sex*region, data=insurance2)
anova(mod2)[3,5]
```

Since the p-value is greater than 0.05, we confirm that this interaction is not significant and we will not include it in our final model.

Finally, we will test the interaction between 'region' and 'smoker'.

```{r echo=FALSE}
ggplot(insurance2, aes(x = paste(region, smoker), y = charges)) + geom_boxplot()
```

Based on the plot, it seems like people who smoke and are from southeast and southwest have significantly higher charges than people who smoke from the northeast and northwest. Again, we will fit the model with the interaction as a predictor to check the significance.

This is the p-value from the test:

```{r echo=FALSE}
mod3 = lm(charges ~ region*smoker, data=insurance2)
anova(mod3)[3,5]
```

The p-value is less than 0.05, indicating that this interaction is significant. We will include it in our final model.

```{r echo=FALSE}
insmodfinal = lm(charges~.+sex:smoker+region:smoker, data=insurance2)
summary(insmodfinal)
```



Section 3: Methodology
You are required to build at least two prediction models using the methods covered in this class. For each model or method you are using, include a brief description of the methodology and a description of the R implementation (R coding steps).

Your should consider the following sub-sections:
Section 3.1: Start with a simple model, a model that doesn't require much training, for example, a linear regression model built after appropriate variable selection and model diagnostics.
Section 3.2: Use the Linear Regression model built in 1 to make predictions on a testing set.
Section 3.3: Fit a different kind of model like a non-parametric regression, regularized regression models or others, and make a prediction on the same testing set.
Section 3.4 (Optional): You can also try with other methods learnt in other classes if applicable (like for example Random Forests).

Section 4: Discussion and conclusions
In this part you should make a summary of your results  by comparing the different modeling approaches and discussing the impact of your analysis. You should also write the main conclusions of your analysis in three to four bullet points.
