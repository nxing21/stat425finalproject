% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
  12pt,
]{article}
\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
  \setmainfont[]{Arial}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage[margin=1in]{geometry}
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdfauthor={Nick Xing: Section 2, combining files; Zihan Zhu: Sections 3 \& 4; Noah Clark: Cover Page \& Section 1, formatting},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{Hospital Insurance Charges Model \vspace{0.5cm}\\
Final for STAT 425}
\author{Nick Xing: Section 2, combining files \and Zihan Zhu: Sections 3
\& 4 \and Noah Clark: Cover Page \& Section 1, formatting}
\date{May 6, 2024}

\begin{document}
\maketitle

{
\setcounter{tocdepth}{3}
\tableofcontents
}
\newpage

\subsection{Section 1: Introduction}\label{section-1-introduction}

This project focuses on the analysis of medical insurance data,
particularly focusing on the medical charges acquired from hospital
visits. The response variable is the variable charges from the insurance
data. This data is found on Kaggle, as was last updated 6 years ago, in
2018. In this data set, there 6 variables excluding the response
variable, charges, which shows the exact charges the patient acquired
from their hospital visit. Each variable is defined within the Kaggle
(2018) website and explained in this order:

\begin{itemize}
\item
  age: Age of primary beneficiary
\item
  sex: Insurance contractor gender (female or male)
\item
  bmi: Body mass index, providing an understanding of body, weights that
  are relatively high or low relative to height, objective index of body
  weight (kg / m \^{} 2) using the ratio of height to weight, ideally
  18.5 to 24.9
\item
  children: Number of children covered by health insurance / Number of
  dependents
\item
  smoker: Smoking (yes or no)
\item
  region: Beneficiary's residential area in the US (northeast,
  southeast, southwest, northwest)
\item
  charges: Individual medical costs billed by health insurance
\end{itemize}

This report compares multiple models derived from analysis of the data
set including a Regression Model, an a Ridge Model, and a Lasso Model.
All analyses are performed in the R environment. This is possible to
recreate with the code provided in this file. Setting seeds might yield
slightly different results; however, we did not use a seed to analyze
this data. No function (i.e.~\emph{set.seed}) should change the results
concluded from this data, although it is possible to slightly alter the
data using said functions. Again, the results would be concluded the
same way. This report has 4 sections. Section 1 is this introduction.
Section 2 uses modelling assumptions and models to analyze the data and
provide insights on the data. Section 3 presents predictive models and
shows training from said models. Section 4 compares models and provides
a discussion of these results.

\newpage

\subsection{Section 2: Exploratory Data
Analysis}\label{section-2-exploratory-data-analysis}

Here is a brief overview of all of the variables of this dataset:

Numerical Variables:

\begin{itemize}
\tightlist
\item
  age: age of primary beneficiary
\item
  bmi: body mass index
\item
  children: number of children/dependents covered by health insurance
\item
  charges (response variable): medical costs billed by health insurance
\end{itemize}

Categorical Variables:

\begin{itemize}
\tightlist
\item
  sex: male or female
\item
  smoker: yes or no
\item
  region: residential area in the US, can be northeast, southeast,
  southwest, or northwest
\end{itemize}

The first step is to check for unusual observations by performing an
outlier test. To do so, we obtained the studentized residuals for our
data, and compared the largest values with the Bonferroni critical
value.

The Bonferroni critical value we calculated is -4.137174. Any
observation with studentized residual higher than the absolute value of
it will be considered an outlier.

Next, here are the five largest studentized residuals, which we will be
comparing to the Bonferroni critical value:

\begin{longtable}[]{@{}lr@{}}
\caption{Largest 5 Studentized Residuals}\tabularnewline
\toprule\noalign{}
Observation Number & Studentized Residual \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
Observation Number & Studentized Residual \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
1301 & 5.009599 \\
578 & 4.219800 \\
243 & 4.053228 \\
220 & 3.998326 \\
517 & 3.863878 \\
\end{longtable}

Since the absolute value of their respective studentized residual is
greater than the Bonferroni critical value, we can conclude that
Observation \#1301 and Observation \#578 are outliers.

We also checked Cook's distance, however we found that there is no point
with Cook's distance greater than 1. We will simply remove the two
outliers we found earlier.

\newpage

After removing these two points, we will be analyzing the predictors to
see if there are any variables we should add or remove.

\includegraphics{finalproject_files/figure-latex/unnamed-chunk-7-1.pdf}

From the plot of charges vs age, we notice a trend that the charges
increase as age increases. We will not be removing `age' as a predictor
since it is clear that it has a significant impact on the response
variable `charges'. This makes sense because as people grow older, their
health declines, and the insurance costs increase.

The charges vs sex boxplot tells us that males tend to have higher
charges than females. We will conduct a t-test to test this difference.

From the t-test, we obtained a p-value of about 0.0346.

Given that the p-value is less than 0.05, we conclude that `sex' is a
significant predictor, with males incurring higher insurance costs than
females. A possible explanation for this is that males are usually more
at risk of health conditions that result in increased charges compared
to females.

From the plot of charges vs bmi, we can see a general trend that as bmi
increases, the charges also increase. As a result, we will not be
removing `bmi' as a predictor since it appears to have an impact on the
response variable. The graph also makes sense logically since people
with a higher bmi tend to be overweight and subsequently, have worse
health than people with a lower bmi, causing their insurance charges to
be greater as well.

The boxplot of charges vs children conveys to us that charges tend to
increase as the number of children grows from 0 or 1 to 2 or 3. While
there are some data points for people with 4 or 5 children, it appears
that these groups have a very low amount of people, and it may be
challenging to draw meaningful conclusions from it. We perform an ANOVA
test to test the significance of `children' as a predictor.

We obtained a p-value of approximately 0.00862.

This p-value is less than 0.05, thus signifying that the predictor
`children' is significant. We will be keeping as a predictor in our
model. A larger number of children/dependents covered leads to higher
charges, as there are more individuals who need to be covered.

From the boxplot of charges vs smoker, it is evident that smokers
generally face significantly higher charges than non-smokers.
Consequently, we will not be removing `smoker' as a predictor. People
who smoke typically incur higher insurance costs due to the health risks
posed by smoking.

The boxplot of charges vs region shows us that the southeast region
seemingly has higher charges than the other three regions. We will
conduct an ANOVA test to make sure that the predictor `region' is
significant.

From the ANOVA test, we obtained a p-value of about 0.0453.

The p-value is less than 0.05, indicating that the predictor `region' is
significant, and thus we will retain it as a predictor. This confirms
that there are regional differences in the insurance costs.

\newpage

Now, we will explore whether or not we should include any interactions
between categorical variables. We will be analyzing all possible
first-order and second-order interactions between our categorical
predictors, including:

\begin{itemize}
\tightlist
\item
  `sex' and `smoker'
\item
  `sex' and `region'
\item
  `region' and `smoker'
\item
  `sex', `smoker', and `region'
\end{itemize}

Here are some plots that show the interactions between these predictors.

\includegraphics{finalproject_files/figure-latex/unnamed-chunk-11-1.pdf}

From the plots, it appears as though smoking increases the charges more
for males than females. Additionally, it seems like smoking has a
greater impact on charges in the southeast and southwest, when compared
to northeast and northwest. However, it does not appear that sex and
region is a significant interaction.

We applied sequential F-tests with the anova function to assess the
significance of the interaction terms in our model. Initially, we
included all potential interactions among the three variables `sex',
`smoker', and `region'. We first found that the second-order interaction
sex:smoker:region had p-value of 0.5733588, so we concluded that it is
not significant and removed it from the model. Subsequently, we tested
the first-order interactions and found that the interaction sex:region
was not significant, since it had p-value of 0.995089. Finally, after
removing sex:region as a predictor, we obtained a p-value of 0.00121263
and 1.478e-05 for sex:smoker and smoker:region, respectively.
Ultimately, we conclude that only the interactions sex:smoker and
smoker:region are statistically significant, and we will retain them in
the final model.

Now, we will examine the numerical variables and see if there is
evidence of any nonlinear trends.

\includegraphics{finalproject_files/figure-latex/unnamed-chunk-16-1.pdf}

Based on the plot of the quadratic fit for charges vs age, we see there
is evidence of non-linearity for the predictor `age' since the quadratic
fit has some upward curvature.

Similarly, based on the plot of the quadratic fit for charges vs bmi, we
see there is some evidence of non-linearity for the predictor `bmi',
although maybe not as clear as for `age'. This time, the quadratic fit
curves downwards.

Finally, the plot of charges vs children also suggests some
non-linearity. However, the non-linearity is not as evident as for `age
and 'bmi' since although the quadratic fit does appear to curve
downwards as the number of children increases, there is not many data
points for 4 and 5 children, so we may not be able to draw a strong
conclusion.

\newpage

\subsection{Section 3: Methodology}\label{section-3-methodology}

\subsubsection{Section 3.1: Simple
Model}\label{section-3.1-simple-model}

Model Selection\\
The choice of linear regression for this analysis is based on its
efficacy in providing a clear and straightforward interpretation of how
various predictors affect insurance charges. Linear regression is
particularly valued for its ability to establish a baseline
understanding of the relationships between variables, offering insights
into the direct impacts of age, BMI, children count, smoking status,sex
and regional differences on insurance costs.

Variable Selection and Diagnostics\\
Age: A continuous variable expected to positively correlate with
insurance charges.\\
BMI: Another continuous variable, which is hypothesized to influence
insurance costs due to its association with health risks.\\
Children: A discrete variable that represents the number of
dependents,potentially affecting insurance premiums.\\
Smoker Status: A categorical variable that significantly impacts
insurance costs, as identified in the exploratory analysis.\\
Sex: A categorical variable, often considered in insurance cost analysis
because gender may influence health risks and insurance premiums.\\
Region: As a categorical variable, the region captures variations in
insurance costs across different geographical locations.\\
Sex and Smoker Interaction: This interaction term examines how gender
and smoking status jointly influence insurance costs. Smokers of
different genders may face different health risks, which can be
reflected in their insurance premiums.\\
Region and Smoker Interaction: This interaction term was included to
examine if the impact of smoking on insurance charges varies by region,
which could suggest regional variations in healthcare costs or lifestyle
patterns.

\begin{longtable}[]{@{}lrrr@{}}
\caption{Variance Inflation Factors of Linear Model}\tabularnewline
\toprule\noalign{}
& GVIF & Df & GVIF\^{}(1/(2*Df)) \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
& GVIF & Df & GVIF\^{}(1/(2*Df)) \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
age & 1.017141 & 1 & 1.008534 \\
bmi & 1.108041 & 1 & 1.052635 \\
children & 1.004025 & 1 & 1.002011 \\
smoker & 1.011905 & 1 & 1.005935 \\
sex & 1.009150 & 1 & 1.004565 \\
region & 1.099632 & 3 & 1.015955 \\
\end{longtable}

Model Diagnostics:\\
The diagnostics conducted include:\\
Multicollinearity Check: The Variance Inflation Factor (VIF) was
calculated for all predictors, with results indicating minimal
multicollinearity among the variables used. VIF values were as follows:
age (1.00), BMI(1.05), children (1.00), smoker status (1.01), sex (1.00)
and region(1.02).

Model Fit: The linear model was fitted with charges as the dependent
variable. The R-squared value of 0.7612 suggests that about 76.12\% of
the variability in insurance charges is explained by the model, which is
quite substantial for a simple linear model.

Residual Analysis: Residuals: The residuals' plot indicated that while
there is some spread, major deviations from normality or constant
variance (homoscedasticity) were not apparent, suggesting that the model
assumptions are reasonably met.

Coefficients:\\
Intercept: The model's intercept is significantly negative, which might
indicate that the baseline insurance charges are negative when all other
variables are zero. This could suggest that further adjustments to the
model might be necessary.

Age: The coefficient for age is significant and positive, indicating
that insurance charges increase with age. This aligns with the general
logic of insurance pricing, where increased age is associated with
higher health risks.

BMI: The coefficient for BMI is also significantly positive, suggesting
that higher BMI is associated with higher insurance charges, likely due
to increased health risks associated with higher BMI.

Children: The coefficient for the number of children is significant and
positive, indicating that having more children leads to higher insurance
charges, possibly reflecting the greater healthcare needs of larger
families.

Significant Impact of Smoking Status: The coefficient for smokers is
significantly higher than for non-smokers, consistent with previous
studies indicating that smoking is a significant factor affecting
insurance costs.

Interactions of Region and Gender: Some regional categories, such as
southeast and southwest, are significant, suggesting that insurance
costs in these regions are higher compared to the baseline region.

Interaction of Smoking Status and Gender: This interaction term is
significant, indicating that the combination of smoking status and
gender has a specific impact on insurance charges, particularly for male
smokers who may face higher charges.

These conclusions suggest that while the overall model performs well,
the impact of certain variables like regions and interaction terms may
require more complex models to more finely interpret these factors'
effects on insurance costs. Further model validation and adjustments are
also necessary to ensure the model's generalization capability and
predictive accuracy across different datasets.

\subsubsection{Section 3.2: Predictions from Simple
Model}\label{section-3.2-predictions-from-simple-model}

Model Implementation:\\
The linear regression model was implemented using the lm() function in
R, focusing on charges as the dependent variable. This model
incorporates several predictors, including age, BMI, number of children,
smoker status, and the interaction between smoker status and region,
which were identified as significant in influencing insurance costs
during the exploratory analysis.

Testing and Predictions:\\
To validate the effectiveness of the linear regression model, the
dataset was split into training and testing subsets. Specifically, 80\%
of the data was used for training the model, and the remaining 20\%
served as the testing set. This division ensures that the model is
tested on unseen data, providing a fair assessment of its predictive
accuracy.

\begin{longtable}[]{@{}lrr@{}}
\caption{Linear Model Predictions Compared to Actual
Data}\tabularnewline
\toprule\noalign{}
& Actual & Predicted \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
& Actual & Predicted \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
5 & 3866.855 & 5801.680 \\
9 & 6406.411 & 8756.868 \\
14 & 11090.718 & 14035.788 \\
19 & 10602.385 & 14611.437 \\
25 & 6203.902 & 7658.894 \\
28 & 12268.632 & 14258.066 \\
\end{longtable}

Predictive Performance Evaluation:\\
The model was fitted on the training data and then used to make
predictions on the testing set. Here are the results of the predictions
for the first few observations:

As observed, the model provides reasonable estimates for the charges,
although there are noticeable differences between the actual and
predicted values, suggesting areas for improvement.

The initial testing indicates that while the linear regression model
captures general trends and is able to provide ballpark estimates of
insurance charges, discrepancies remain between predicted and actual
charges. These differences highlight the potential need for more complex
models that could better account for nuances in the data not captured by
this simple linear model. The following sections will explore such
models, comparing their predictions with those of the baseline linear
model to identify the most effective approach for predicting insurance
charges.

\subsubsection{Section 3.3: Advanced
Models}\label{section-3.3-advanced-models}

Model Types:\\
Regularized Regression: To enhance the predictive accuracy and manage
potential issues of multicollinearity and overfitting present in our
linear regression model, we employed advanced modeling techniques such
as Ridge and Lasso regression. These methods are forms of regularized
regression that include a penalty term to the loss function:

Ridge Regression (L2 regularization): Adds a penalty equal to the square
of the magnitude of coefficients. This method is particularly effective
in reducing the model complexity while still allowing the use of all
variables. It helps in handling multicollinearity, preventing
overfitting by shrinking the coefficients.

Lasso Regression (L1 regularization): Adds a penalty equivalent to the
absolute value of the magnitude of coefficients. Unlike Ridge, Lasso can
completely eliminate the weight of less important variables by setting
their coefficients to zero. This results in feature selection within the
model, which is beneficial when we need a sparse model with fewer
variables.

Implementation and Predictions: Both models were implemented using the
glmnet package in R, which efficiently handles large datasets and
complex models with its capabilities for both Lasso and Ridge
regression. The matrix of predictors x was derived from the training
data, excluding the intercept to allow glmnet to handle regularization
properly. The regularization parameter s was set to 0.01 for both
models. This choice is typically subject to tuning through methods like
cross-validation, but for simplicity, we've chosen a small but non-zero
value, which demonstrates regularization without overly constraining the
models.

Predictive Performance Evaluation: The predictions made by the Ridge and
Lasso models on the testing set were compared with the actual charges
and those predicted by the simple linear model.

\begin{longtable}[]{@{}lrrrr@{}}
\caption{Actual Data Compared to Predictive Models}\tabularnewline
\toprule\noalign{}
& Actual & Linear & Ridge & Lasso \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
& Actual & Linear & Ridge & Lasso \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
5 & 3866.855 & 5801.680 & 5976.579 & 5894.958 \\
9 & 6406.411 & 8756.868 & 8931.156 & 8638.090 \\
14 & 11090.718 & 14035.788 & 14047.500 & 14047.158 \\
19 & 10602.385 & 14611.437 & 14110.493 & 14658.892 \\
25 & 6203.902 & 7658.894 & 7695.461 & 7725.347 \\
28 & 12268.632 & 14258.066 & 14087.683 & 14248.724 \\
\end{longtable}

Comparison and Conclusions:\\
The Ridge and Lasso models both adjusted the predictions closer to
actual values in some cases, compared to the basic linear model.
However, they also introduced some variability, likely due to the
influence of the regularization term balancing bias and variance
differently:

Ridge Model: It generally increased the estimates, potentially due to
its nature of shrinking coefficients but not setting them to zero, thus
still considering all input features.

Lasso Model: It showed a trend similar to the linear model but with
slight adjustments, indicating that it might be dropping some less
influential variables from the model.

These results suggest that while both Ridge and Lasso offer advantages
in terms of handling overfitting and multicollinearity, the choice
between them would depend on the specific characteristics of the dataset
and the goal of the analysis, with Lasso providing a sparser solution
and Ridge offering stability across a broader range of data conditions.
Further model tuning and cross-validation would be necessary to optimize
their performances and fully assess their effectiveness compared to the
simple linear model.

\newpage

\subsection{Section 4: Discussion and
Conclusions}\label{section-4-discussion-and-conclusions}

\textbf{Summary of Results}\\
In this analysis, we employed various statistical models to predict
health insurance costs using a dataset that included variables such as
age, BMI, number of children, smoker status, sex and regional
interactions. The results can be summarized as follows:

Linear Regression Model: Provided a solid baseline for understanding how
different variables impact insurance costs. Significant predictors
included age, BMI, and especially smoker status, which greatly increased
predicted charges. However, the model sometimes overestimated or
underestimated charges significantly.\\
Ridge Regression Model: Adjusted predictions closer to actual values in
some instances, suggesting its effectiveness in handling
multicollinearity by shrinking coefficients but considering all
variables.\\
Lasso Regression Model: Offered predictions similar to the linear model
but with adjustments likely due to its feature selection capability,
which dropped less influential predictors.

For the predictions, we apply to the test data set all the
transformations made to the train data set. For each model, the
predictions are obtained using the same command predict, and we evaluate
the residual sum of squares, RSS.

\begin{longtable}[]{@{}lr@{}}
\caption{RSS Comparison of Models}\tabularnewline
\toprule\noalign{}
Model & RSS \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
Model & RSS \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Linear Regression & 10162756224 \\
Ridge Regression & 10163886527 \\
Lasso Regression & 10159739488 \\
\end{longtable}

Comparative analysis showed that while the linear model was useful for
understanding direct relationships and setting a baseline, both Ridge
and Lasso provided nuanced insights by addressing overfitting and
highlighting essential predictors, but the Lasso regression model
performs the best on the testing dataset.However, specific model
selection should also consider other factors such as model
interpretability, computational complexity, and so on.

\textbf{Impact of Analysis}\\
This analysis significantly enhances our understanding of factors
influencing health insurance costs:

Smoker Status: Emerged as a critical determinant of insurance costs,
with smokers incurring significantly higher charges. This highlights the
potential for insurance companies to adjust premiums or offer programs
encouraging smoking cessation.

Age and BMI: Both variables were also strong predictors of costs,
aligning with expected health risk increases with age and higher BMI.

Regional Differences: The interaction terms suggested that regional
factors might also play a role in insurance costs, potentially due to
environmental, policy, or lifestyle differences.

\textbf{Conclusions}\\
Smoking status is the most potent predictor of health insurance charges,
suggesting targeted health initiatives could be beneficial. Age and BMI
are important factors in predicting insurance costs, indicating that
personalized insurance plans could be more effective. Regularized
regression models (Ridge and Lasso) are valuable for refining
predictions and identifying key predictors, particularly in datasets
prone to multicollinearity.

\end{document}
